

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- region SEO -->
    <title></title>
    <meta name="description" content=""/>

    <meta property="og:title" content="">
    <meta property="og:description" content="">
    <!-- endregion SEO -->

    <!-- region Styles -->

    <!-- region Noto Sans Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100..900;1,100..900&display=swap"
          rel="stylesheet">
    <!-- endregion Noto Sans Font -->

    <!-- region Tailwind Compiled Styles -->
    <link rel="stylesheet" type="text/css" href="/static/output.css">
    <!-- endregion Tailwind Compiled Styles -->

    <!-- region Custom styles -->
    
    <!-- endregion Custom styles -->

    <!-- endregion Styles -->
</head>

<!-- region GA & YaMetrika -->

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5WTE0KE6PT"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-5WTE0KE6PT');
    </script>
    <!-- Yandex.Metrika counter -->
    <script type="text/javascript">
        (function (m, e, t, r, i, k, a) {
            m[i] = m[i] || function () {
                (m[i].a = m[i].a || []).push(arguments)
            };
            m[i].l = 1 * new Date();
            for (var j = 0; j < document.scripts.length; j++) {
                if (document.scripts[j].src === r) {
                    return;
                }
            }
            k = e.createElement(t), a = e.getElementsByTagName(t)[0], k.async = 1, k.src = r, a.parentNode.insertBefore(k, a)
        })
        (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

        ym(82960681, "init", {
            clickmap: true,
            trackLinks: true,
            accurateTrackBounce: true
        });
    </script>
    <noscript>
        <div><img src="https://mc.yandex.ru/watch/82960681" style="position:absolute; left:-9999px;" alt=""/></div>
    </noscript>
    <!-- /Yandex.Metrika counter -->

<!-- endregion GA & YaMetrika -->

<body class="max-w-[1000px]">

<header class="text-sm breadcrumbs border-neutral border-b">
    <ul class="!pl-2">
        
            
                <li>
                    
                        <a href="/">п⌀тик.ио</a>
                    
                </li>
            
                <li>
                    
                        <a href="/books">Библиотека</a>
                    
                </li>
            
                <li>
                    
                        Кабанчик
                    
                </li>
            
        


    </ul>
</header>

<main class="prose  max-w-none p-2">
    
        <h1>Высоконагруженные приложения. Программирование, масштабирование, поддержка</h1>
        <cite class="block">Клеппман Мартин</cite>
    

    
    
        <cite class="block">Eng: Designing Data-Intensive Applications</cite>
    

    
        <a class="btn btn-sm" href="https://drive.google.com/file/d/1-ddqdDJ01-Y7sLo6dEDCRPiJFk1Q4GSO/view?usp=drive_link">pdf</a>
    

    <h2>Чем интересна</h2>
    <div>
        Легендарная книга с Кабанчиком. Рассматриваются всякие бекенд штуки: внутреннее устройство бд, паттерны использования бд. Полезна для собесов и для работы.
    </div>

    <h2>Саммари</h2>
    <div>
        <h3>Основы информационных систем</h3>
<h4>Надежность, масштабируемость, удобство</h4>
<ul>
<li><strong>Надёжность</strong> - как система реагирует на сбои</li>
<li>Сбой - когда кусочек системы работает ненормально</li>
<li>Отказ - когда вся система не работает</li>
</ul>
<p>Чтобы система была устройства к сбоям, и чтобы это не переходило в отказ, нужно постоянно тестировать систему,
искусственно вызывая сбои (например что-то отключать, и проверять, что система работает)</p>
<p>Виды сбоев:</p>
<ul>
<li><p>Аппаратные сбои - когда железо хромает, помогает сделать несколько железяк (напр raid массивы)</p>
</li>
<li><p>Программные сбои - ну понятно, всякие кейсы когда сторонние системы не робят, лечится допущениями и ретраями</p>
</li>
<li><p>Человеческий фактор - тоже понятно, когда чето неправильно настроили, лечится откатами, песочницей, тестированием,
метрики</p>
</li>
<li><p><strong>Масштабируемость</strong> - как система реагирует на возросшую нагрузки</p>
</li>
</ul>
<p>Важно понимать что нагрузка возросла. Для этого используются <em>параметры нагрузки</em></p>
<p>Примеры параметров нагрузки: запросы в секунду, соотношение операций записи и чтения</p>
<p>Способы чтения на примере тви:</p>
<ul>
<li>все твиты в однну табличку, затем для получения фида делаем джоин по подпискам</li>
<li>другой подход делаем кеши с фидами и при публикации твита вставляем в каждый фид</li>
<li>второй вар работал лучше потому что кол-во записей меньше кол-ва чтений</li>
<li>Но когда подписчиков много, то это жестко - запись в лям фидов</li>
<li>Так что можно использовать гибридный подход</li>
</ul>
<p>Время ответа хорошо трекать с помощью перцентилей:</p>
<ul>
<li>50 перцентиль - медиана</li>
<li>Перцентили выше (95, 99) могут быть важны в случае больших запросов от клиентов (напр большая корзина)</li>
</ul>
<p>Виды масштабирования:</p>
<ul>
<li>Масштабирование вертикальное - качаем одну машину</li>
<li>Горизонтальное - качаем количество машин</li>
<li>На практике можно комбинировать - несколько мощных тачек</li>
<li>Авто масштабирование - когда на основе нагрузки поднимаются новые тачки</li>
<li>Можно и в ручную делать, тоже норм варик, не будет неожиданностей (типа бессмысленного прироста тачек при ддос атаке)</li>
</ul>
<p>Универсальной архитектуры не существует, всегда все зависит от параметров нагрузки, хотя есть паттерны масштабирования</p>
<p><strong>Удобство сопровождения</strong> - когда мало Легаси; также включает в себя эксплуатацию, простоту и расширяемость</p>
<ul>
<li><em>Эксплуатация</em> - удобство работы системы для операторов</li>
<li>Операторы оч важны, и хорошие операторы могут работать и с плохими системами</li>
<li>В обязанности оператораров входят различные типовые операции, удобство эксплуатации заключается в автоматизации таких
операций</li>
<li><em>Простота</em> - ну понятно, если сложно, то сложно</li>
<li>Чтобы уменьшить сложность, можно накидать слои абстракции (напр юзать высокоуровневые языки по сравнению с
низкоуровневыми)</li>
</ul>
<h4>Модели данных и языки запросов</h4>
<ul>
<li>SQL = отношения (таблицы) с кортежами (строками)</li>
<li>NoSQL = Not Only SQL</li>
</ul>
<p>Причины появления NoSQL:</p>
<ul>
<li>Новые возможности масштабирования</li>
<li>Осс &gt; клозед сурс</li>
<li>Более сложные запросы</li>
<li>Динамические схемы</li>
<li>Объектно-реляционное несоответствие<ul>
<li>Модели в коде могут иметь сложные связи, типа массива</li>
<li>В случае sql нужно делать хуилиард таблиц, и джоинить</li>
<li>А в случае NoSQL можно выразить все одним jsonом</li>
<li>Хотя и в sql можно json-поля сделать</li>
</ul>
</li>
</ul>
<h5>Связи «многие-к-одному» и «многие-ко-многим»-</h5>
<p>Можно хранить повторяющиеся данные (напр. должность) текстом, можно ФК на табличку использовать:</p>
<ul>
<li>Если текст, то будет жёсткое дублирование, и при замене может возникнуть ситуация когда что-то обновилось, а что-то
нет</li>
<li>Использование фк удобнее, потому что единообразие, удобно редачить, поиск удобный, локализацию можно сделать</li>
<li>Использование фк вместо текста называется <em>нормализацией</em></li>
<li>Соответственно <em>денормализация</em> - наоборот когда используется текст вместо фк</li>
</ul>
<p>Поначалу может показаться что делать строки это просто и удобно, но потом текст может разразрастись до сущности (
название компании &gt; сущность компания) - так появляется связь многие ко многим</p>
<p>Ни реляционная модель, ни документоориентированная модель не может быть универсальной в контексте простоты кода
приложения. Так документоориентированная модель сосет когда в приложении много связей, приходится делать несколько
запросов к бд и склеивать данные, что усложняет код</p>
<h5>Динамическая и строгая схемы данных</h5>
<ul>
<li>Динамическая схема = Неструктурированная модель в документоориентированной бд = schema less = <em>schema on read</em> - то
есть
проверка типов происходит в коде; это удобно когда данные могут быть разных типов (кейс сторонних систем)</li>
<li>Строгая схема = Реляционный подход = <em>schema on write</em> - когда мы записываем данные и они будут соответствовать схеме
данных; и при чтении необязательно проверять типы, они также будут соответствовать схеме</li>
<li>Динамическую схему очевидно проще менять: так если хотим разбить имя на имя и фамилию, достаточно написать код; в то
время как для строгой схемы нужно писать миграцию.</li>
<li>В некоторых СУБД (мускуль) миграция может вызвать простой системы,
тк
применение миграции занимает много времени, обойти это можно используя утилиты или в случае с update (которая может
тормозить в любой бд) можно выставить значение по умолчанию и заполнять в коде</li>
<li><em>Локальность данных</em> = все в одном месте (не разнесено по нескольким таблицам) хороша когда используются все данные (
кейс
веб странички); но при этом документ выгружается целиком, что может быть не экономно. Аналогично при записи документ
перезаписывается целиком, что тоже может занимать больше времени по сравнению с реляционной бд; так что лучше когда
документы мелкие</li>
</ul>
<h5>Декларативный и императивный подходы</h5>
<ul>
<li>SQL - декларативный подход к запросу данных, то есть мы пишем лишь то, что нам нужно, используя ограниченный
синтаксис,
а как данные будут получены решает оптимизатор. Также такой подход облегчает внутренние оптимизации и параллелизм.</li>
<li>Императивный подход напротив требует написания кода: например получаем все доки, итерируемся по ним в цикле, фильтруя
данные</li>
<li>Ещё пример декларативного подхода - css по сравнению с js. Поиск css-селектора осуществляется браузером, так что
создатели браузера могут оптимизировать его работу и не нужно будет переписывать код, js-код по поиску элемента
оптимизируешь только ты, и придется менять код</li>
<li>MapReduce - гибридный подход - пишешь чистые функции, которые могут выполняться в любом порядке и параллельно<ul>
<li>Минус - в отсутствии декларативности</li>
<li>но в монге есть aggregation pipeline синтаксис, который позволяет писать
мап-редьюс с помощью ограниченного синтаксиса, что обеспечивает внутреннюю оптимизацию</li>
</ul>
</li>
</ul>
<h5>Графовые модели данных</h5>
<ul>
<li>Графовые модели данных - соцсети, ссылки на веб страницах, дороги</li>
<li>Граф состоит из вершин и ребер</li>
<li>Алгоритмы на графах поиск кратчайшего пути для автомобилей, pageRank для рейтинга веб страниц</li>
</ul>
<p><strong>Графы свойств</strong></p>
<ul>
<li>Графы свойств - neo4j, titan, infinite graph</li>
<li>Вершины содержат айди, входящие и исходящие ребра и произвольные свойства</li>
<li>Ребра содержат айди, начальные и конечные вершины и произвольные свойства</li>
<li>И на основе этих данных можно соединять ребрами любые вершины, совершать обход графа, и хранить разную информации</li>
</ul>
<p>Графы хороши тем что их можно расширять:</p>
<ul>
<li>например у нас есть два человека (2 вершины), два города, в которых они
родились (2 вершины, но уже другая сущность), и два аллергена, на которые у них аллергия (опять 2 вершины с другим
смыслом),</li>
<li>таким образом можно получить у каких людей аллергия на определенный продукт или по стране получить ее
граждан (то есть довольно гибко)</li>
</ul>
<p>Cypher - язык запросов для графов (neo4j), там все стрелочками отписывается, плюс он декларативный, что хорошо</p>
<p>Все это можно реализовать как 2 таблицы - таблица вершин и таблица ребер, и использовать обычный SQL, но запрос будет
больше и сложнее для понимания, так что своей задаче - свой инструмент</p>
<p><strong>Тройные кортежи = Turtle формат = N3 (notation 3)</strong></p>
<ul>
<li>Субъект, предикат, объект</li>
<li>Если объект - примитив (число, строка), то предикат и объект - пара ключ-значение (Маша, возраст, 20 =&gt; возраст=20)</li>
<li>Если объект - вершина, то предикат - ребро (Маша, жената на, Пете =&gt; Маша и Петя - вершины, жената на - ребро)</li>
<li>Семантическая паутина = RDF - альтернативный способ записи тройных кортежей для веб страниц в xml-формате</li>
<li>SPARQL - язык запросов для тройных кортежей</li>
<li>Datalog - предшественник Cypher и SPARQL; сам язык - подмножество Prolog - так что это логическое программирование;</li>
<li>Cascalog - Hadoop реализация языка</li>
</ul>
<h4>Подсистемы хранения и извлечения данных</h4>
<p>Структуры данных SQL = подсистемы хранения = Log-structured и page-oriented</p>
<p><strong>Log-structured подход и Индексы</strong></p>
<ul>
<li>Log-structured - данные записываются в конец файла (журнала, log)</li>
<li>Индекс - структура данных для поиска, производная от данных</li>
<li>Индексы можно добавлять и удалять, не затрагивая содержимое бд</li>
<li>Поддержка индексов требует затрат на запись. Любая запись в бд будет сопровождаться обновлением индекса</li>
<li>Так что индексы ускоряют чтение, но замедляют запись, и создание индексов лежит на плечах у разраба</li>
</ul>
<p><strong>Хеш-индекс</strong></p>
<ul>
<li><p>Допустим бд - файл со строками ключ-значение, тогда можно сделать хеш-таблицу, где ключ - это ключ строки бд, а
значение - номер строки, тогда при поиске значения по ключу, вместо полного перебора строк файла, мы получим из
хеш-таблицы номер строки и там будет искомое значение ключа</p>
</li>
<li><p>Хеш-индекс используется в системе хранения Bitcask в NoSQL бд Riak, и такую систему хорошо использовать для счётчиков
просмотров</p>
</li>
<li><p>При log-structured подходе есть проблема того, что файл с логом будет большим, решается она разбивкой файла на
несколько
файлов лимитированного размера (сегменты) + применение уплотнения (compaction) - т.е. отбрасывание дублирующихся
ключей</p>
</li>
<li><p>Затем получившиеся стройные файлы можно слить</p>
</li>
<li><p>Таким образом получаем файлы-сегменты и по ним строим хеш-таблицы
и храним в ореративе</p>
</li>
</ul>
<p>Типовые проблемы и решения при таком подходе:</p>
<ul>
<li>Формат файла - бинарный</li>
<li>Удаление - делаем спец метку (tombstone), которая говорит о том что нужно игнорировать предыдущие значения ключа</li>
<li>Сбои - чтобы не считать заново хеш-таблицы, можно хранить их на диске</li>
<li>Недописанное записи - используем контрольные суммы</li>
<li>Конкурентный доступ - несколько файлов и несколько сегментов - значит можно параллелить чтение</li>
<li>Почему запись в конец файла? Потому что быстрые операции, лёгкость конкурентного доступа и восстановления, решение
проблемы фрагментирования</li>
<li>Ограничения хеш-таблиц: они должны помещаться в оперативу, и запросы по диапазону неэффективны</li>
</ul>
<h5>Ss-таблицы и lsm-деревья</h5>
<ul>
<li>Ss-таблица (sorted string table) - формат файла, где ключи отсортированы + ключ встречается в сегменте один раз</li>
<li>Формирование ss-таблицы получается путем эффективного слияния нескольких сегментов в блок</li>
<li>Индекс при этом получается разряженным (не обязан хранить все ключи), и можно искать ключ используя факт что он
находится между двумя другими ключами</li>
<li>Сами блоки небольшого размера, по ним быстро происходит чтение + можно сжать</li>
<li>Как происходит вставка с сохранением порядка? Используются деревья (красно-черные, avl) - memtable - которые
размещаются
в оперативе</li>
<li>Когда размер memtable достигает лимита, то сохраняем ss-table на диск</li>
<li>Также ведём журнал с записью в конец для кейса восстановления</li>
<li>Этот алгоритм используется в подсистемах хранения LevelDb и RocksDb, которые используются в Riak. Также аналогичная
подсистема в Cassandra и HBase.</li>
<li>Вся эта система (с уплотнением, слиянием отсортированных файлов) называется LSM  (Log-Structured Merge-Tree)</li>
<li>Также похожий принцип используется в Lucene - поисковый движок, на котором работает Elastic Search. Ключ-значение
состоит из терма и списка айди документов, которые содержат терм</li>
<li>У такой системы есть проблема: поиск ключей, которых нет, может занимать много времени - но для этого есть спец
структуры данных, типа Фильтр Блума</li>
<li>Уплотнение и слияние бывает разным: size-tiered compaction, leveled compaction</li>
</ul>
<h5>B-деревья</h5>
<ul>
<li>Хранят пары Ключ-значение, ключи отсортированы</li>
<li>В отличие от LSM, данные разбиваются не на сегменты переменного размера, а на блоки/страницы фиксированного размера,
аналогично разбивке на диске</li>
<li>Каждый блок имеет ссылку на другой блок, так можно создать дерево страниц, по которому просто искать</li>
<li>Одна из страниц - корневая, представляет из себя ключи и ссылки на дочерние страницы; ключи указывают диапазон страниц</li>
<li>То есть
<code>10 (граничный ключ) ссылка (на диапазон страниц в границах ключей) 20 (второй граничный ключ)</code></li>
<li>При поиске постепенно сужаются границы ключей, и мы попадаем в страницу-лист, где ключу соответствует значение</li>
<li>Branching factor - кол-во ссылок на дочерние страницы, зависит от дискового пространства</li>
<li>Запись значения происходит как и поиск - O(log n). Если место кончилось, то блок разбивается на два, и родитель
обновляется</li>
<li>Отказоустойчивость достигается с помощью WAL (write ahead log) = redo log - куда записывается операция записи в
b-дерево
до совершения операции</li>
<li>Конкурентная запись происходит с помощью latch - облегченный вариант блокировок</li>
</ul>
<p>Усовершенствования b-деревьев:</p>
<ul>
<li>вместо перезаписи использовать копирование страницы, так улучшится восстановление и конкурентная запись</li>
<li>граничные ключи можно сжимать, чтобы в блок попало больше ключей и уменьшилось количество уровней</li>
<li>дополнительные указатели на блоки на одном уровне - ускорение поиска нескольких ключей без надобности возвращаться к
родителям</li>
<li>фрактальные деревья - микс с lsm-деревьями</li>
</ul>
<p>Сравнение b-tree и lsm-tree:</p>
<ul>
<li>Чтение: B-tree &gt; LSM-tree</li>
<li>Запись: B-tree&lt; Lsm-tree</li>
<li>Размер на диске: B-tree&lt; Lsm-tree</li>
</ul>
<h5>Минусы LSM</h5>
<ul>
<li>Уплотнение может занимать время, и время на больших перцентилях возрастёт</li>
<li>Большое количество операций на запись отсравивает уплотнение, что замедляет чтение</li>
</ul>
<h5>Еще про индексы</h5>
<ul>
<li>Вторичные индексы - индексы по столбцам, не являющихся первичными ключами</li>
<li>Значение ключа в индексе может быть строкой (напр айди записи), может быть ссылкой на кучу - heap file, где хранится
строка. Использование кучт хорошо чтобы избавиться от дубликатов</li>
<li>Ходить в кучу бывает не оч эффективно, тогда хранят строку, то есть индекс кластерный</li>
<li>Covering index = index with included columns - использование обоих подходов.</li>
<li>Когда запрос можно выполнить используя только данные из индекса - значит индекс охватывает запрос</li>
<li>Concatenated index - когда ключ состоит из нескольких полей (фамилия и имя), при этом важен порядок! (Поиск по имени
бесполезен)</li>
<li>Многомерные индексы - когда ищем по области (поиск ресторанов в промежутке координат) - R-дерево</li>
<li>Fuzzy-запросы - когда ищем текст с ошибками. Помогает использование редакторского расстояния.</li>
<li>In-memory db - когда храним все в оперативе, примеры: redis, memcache. Для надёжности можно делать слепки на диск,
использовать спец железо, журналирование и тд. Если место кончается, то можно использовать антикеширование - старье на
диск складывать</li>
</ul>
<h5>OLAP</h5>
<ul>
<li>Oltp - обработка транзакций в реальном времени - чтение небольшого количества записей, пользователь интерактивно
добавляет/меняет записи, скорость выполнения транзакций должна быть высокой</li>
<li>Olap - аналитическая обработка данных в реальном времени - всякая статистика - обработка большого количества записей ,
причем лишь некоторых столбцов; запросы могут выполняться долго</li>
<li>Data warehouse - склад данных - бд для аналитики</li>
<li>ETL - extract - transform - load - процесс загрузки данных из oltp баз в data warehouse</li>
<li>Примеры data warehouse: Teradata, Vertica, SAP HANA, ParAccel (Amazon Redshift), Hive, Spark, Big Query.</li>
<li>Схема Звезда - типовая модель данных в складах данных. Ключевая сущность - таблица фактов - таблица из событий,
которые состоят из столбцов (зачастую фк) других таблиц - таблиц изменений</li>
<li>Схема Снежинка - подвид звезды, но таблицы изменений разбиваются на подизмерения</li>
<li>В складах данных данные располагаются не построчно, а по столбцам - так в запросах, которые аггрегируют несколько
полей, не придется грузить строки, в которых столбцов может быть сильно больше чем в запросе</li>
<li>Также для оптимизации столбцы можно сжать, тк значения в них повторяется. Типовой метод сжатия - bitmap encoding -
значения перебираются, и результат кодирование это количество нулей (значение отсутствует) и количество единиц (подряд
идущие позиции:
1 2 3 3 =&gt;
1 - 0 1
2 - 1 1
3 - 2 2</li>
<li>Если нулей много, то битмапа разряжена, и ее можно дополнительно сжать алгоритмом кодирования длин серий</li>
<li>Модели данных в Cassandra, HBase, BigTable используют понятие column family - это не то же самое что столбчатое
хранилище</li>
<li>На уровне железа для хранилищ данных применяется векторизированная обработка</li>
<li>Сортировка строк по определённым столбцам имеет смысл для более эффективного поиска, и более эффективного сжатия</li>
<li>Также можно хранить несколько сортировок (используется в Vertica)</li>
<li>Материализованные сводные показатели - речь об агрегируемых функциях типа sum, и о том почему бы их не кешировать.</li>
<li>Один из способов - materialized view - похоже на обычный view в бд (сокращенная форма запроса), но это именно
результат выполнения запроса</li>
<li>Data Cube = OLAP Cube - частный случай materialized view - сетка показателей по данным столбцов</li>
<li>Важно понимать что materialized view полезны лишь для некоторых запросов</li>
</ul>
<h4>Кодирование и эволюция</h4>
<ul>
<li>Rolling update= staged rollout - постепенный деплой - когда сервер развернут на нескольких инстанцах, обновление
происходит не сразу а постепенно, по инстансу за раз, проверяя все ли ок</li>
<li>При обновлении приложения - тут сам клиент решает обновляться ли ему</li>
</ul>
<p>Совместимость:</p>
<ul>
<li>Обратная совместимость - новый код способен читать старые данные</li>
<li>Прямая совместимость - старый код может читать новые данные</li>
</ul>
<h5>Сериализация</h5>
<p>Данные приложения могут быть в двух состояниях: в виде объектов и структур данных в оперативе, либо в виде
последовательности байтов (Напр. Json) при передаче данных по сети или хранении на диске</p>
<p>Процесс перевода данных из формата оперативы в формат для передачи называется encoding=serialization=marshalling, а
обратный процесс - deciding=deserialization=parsing=demarshaling</p>
<p>Языки программирования предоставляют свой способ сериализации данных, напр pickle в Python, но это работает только в
рамках одного языка, не очень безопасно, контроль версий хромает, и производительность тоже
может хромать</p>
<p>Json, xml, csv - популярные, человеко-читаемые текстовые форматы данных. Но у них есть некоторые проблемы: отсутствие
возможности указания точности чисел и больших чисел, отсутствие
возможности
передавать двоичные данные (но обходится с помощью base64 кодирования, но и увеличивает размер данных), в коже
приходится зашивать логику парсинга, и csv довольно хрупкий формат</p>
<h5>Бинарные форматы</h5>
<p>Двоичное кодирование имеет смысл когда данных много</p>
<p>Для json и xml есть свои бинарные аналоги, типа messagepack, bson, wbxml, хотя они не сильно экономят место</p>
<p>Thrift и Protocol Buffers - либы двоичного кодирования, обе работают на основе схемы (на своем языке), по этой схеме
можно генерировать код. Суть кодирования в применении тегов полей - вместо хранения названия поля, просто храним цифру.
Совместимость обеспечивается за счёт того что новые добавляемые поля - необязательны</p>
<p>Avro - ещё один двоичный формат, применяемый в Hadoop, там все завязано на порядке полей. Есть два типа схем, схема
чтения (та что в коде), схема записи (мб в файле с данными, в бд, при согласовании при отправке по сети), и они могут не
совпадать, таким образом можно осуществлять эволюцию схемы. Ещё плюсом Avro является возможность генерировать схему на
лету, например из схемы бд, и забекапить бд в двоичном формате</p>
<p>Кодогенарция для бинарных форматов актуальна только для статически типизированных языков, также есть специальный язык
обработки данных Apache Pig</p>
<h5>Передача данных</h5>
<p>Данные передаются на разных уровнях: на уровне бд, на уровне сети, при асинхронном общении</p>
<p>При передаче данных на уровне бд может быть ситуация, когда схема обновилась, а часть инстанцев ещё нет, тут важно
обеспечить прямую совместимость и чтобы если новый инстанц записал данные в новое поле, важно чтобы старый код не стёр
эти новые данные при записи</p>
<p>И ещё раз нужно быть аккуратнее с миграцией данных, когда старые данные обновляются на новый лад, это тяжёлая операция</p>
<p>Сервис - то что предоставляет апи</p>
<p>Сервис-ориентироаанная арх= микросервиснач арх - когда у сервиса своя задача, напр сервер работает с бд</p>
<p>Веб-сервис - сервис использующий хттп</p>
<p>Rest и soap - 2 подхода к написанию веб сервисов</p>
<p>Rest(ful) подход: применение урла для доступа к ресурсам, активное использование возможностей хттп: аутентификация,
кешироаание, часто используется json, с помощью которого можно генерить доку и код (openapi, swagger)</p>
<p>Soap - xml подход, не использует возможности хттп, а свои спеки, описываемые с помощью wsdl. Этот подход сильно
завязывается на спец утилитах, так что где-то интеграцию с соап сделать сложно</p>

    </div>


</main>

<footer class="prose max-w-none border-t border-neutral mt-4 p-2">
    <div class="flex justify-end gap-2 text-sm">
        <a href="https://t.me/potyk_forever">канал</a> •
        <a href="https://t.me/potykion">автор</a>
    </div>
</footer>

</body>



</html>